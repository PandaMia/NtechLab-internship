# Задание 2

## Описание задачи  

Необходимо обучить нейросеть, способную по входному изображению лица определять пол человека на изображении.

## Описание файлов

- *Gender_recognizer.ipynb* -- notebook-файл с кодом загрузки изображений, а также построения, тренировки и оценки качества нейронной сети
- *model_state-epoch-20-val_acc-0.9619.pth* -- модель обученной нейронной сети
- *process.py* -- скрипт для использования нейросети, с помощью которого можно просчитать переданную через аргументы папку с изображениями 

## Описание решения  
Для предобработки данных и построения модели нейросети я использую *pytorch*
#### Загрузка данных
Для подачи изображений на вход нейронной сети их необходимо преобразовать к единому формату.  
Я привел размеры изображений к формату 64х64, чтобы обучение нейронной сети заняло приемлемое время. 
Преобразование изображений к более высокому разрешению существенно увеличивало время обучения. 
С учётом того, что обучение я осуществлял на CPU, пришлось пожертвовать качеством картинок.  

Далее с помощью функции random_split я разбил датасет на тренировочный, валидационный и тестовый наборы данных для обучения и оценки качества нейронной сети. 
После этого загрузил наборы данных через DataLoader с указанием размера минивыборки, 
а также параметрами последовательной/перемешанной загрузки данных и многопоточности.  

Используемая в задаче метрика качества accuracy может быть не очень показательной в случаях, когда есть сильный перевес по количеству объектов в сторону одного из классов. 
Поэтому полезно убедиться, что объекты исходного набора данных распределены равномерно. 
Для визуализации распределения классов я построил соответствующие гистограммы (см. *Gender_recognizer.ipynb*).  

#### Описание модели  

Выбранная модель имеет 3 сверточных слоя и 2 линейных слоя:  
(conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))  
(conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))  
(conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))  
(fc1): Linear(in_features=128, out_features=256, bias=True)
(fc2): Linear(in_features=256, out_features=2, bias=True)  

К каждому сверточному слою применяется слой пуллинга:  
(pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)  

Для избежания переобучения нейронной сети я также добавил также несколько слоев dropout:  
(drop2d): Dropout2d(p=0.25, inplace=False) - после каждого слоя сжатия  
(drop): Dropout(p=0.5, inplace=False) - после первого полносвязного слоя  

Я использую CrossEntropyLoss в качестве функции потерь и оптимизатор Adam с коэффициентом обучения 0.0003.  
Метрикой оценки качества нейронной сети является accuracy.

#### Параметры обучения

Обучение нейросети происходило на 20 эпохах с размером минивыборки: 64 изображения.
В процессе тренировки я сохранял историю обучения для дальнейшей визуализации. 
Кроме этого, каждую эпоху я сохранял состояние нейросети для возможности выбора оптимальной модели и отката к более раннему состоянию.

#### Результаты обучения  

К концу обучения рост качества на валидационной выборке замедлился. Доля правильных ответов варьируется в районе 96%.  
Обучение нейронной сети заняло три с половиной часа.

В итоге после 20 эпох обучения модель показала на тестовой выборке качество 96.35% с показателем ошибки 0.0936.  
Данная модель прилагается в качестве ответа на задание.

## Инструкция для запуска тренировки нейросети  

Запустить тренировку нейросети можно с использованием notebook-файла *Gender_recognizer.ipynb*  
Обучающие данные необходимо разместить в директориях */data/female* и */data/male*

## Инструкция для запуска скрипта *process.py*  

В командной строке перейти в директорию с файлом *process.py*  
Файл с тестируемой моделью (*model_state-epoch-20-val_acc-0.9619.pth*) должен находиться в одной директории с запускаемым файлом *process.py*

В командной строке ввести команду:  
*python process.py folder/to/process*  
где *folder/to/process* путь к изображениям  

Скрипт сохраняет файл *process_results.json* с информацией о результатах процессинга (в директорию, где находится *process.py*).
